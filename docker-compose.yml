version: '2'
services:

# The CLI container is used to execute Conjur commands. As the CLI is the
# admin UI for Conjur, this affords a way to protect access to it.
# It also makes managing multi-version Conjur environments easier.

  conjur1:
    image: conjur-appliance:latest
    container_name: conjur1     # important that container name == service name
    labels:
      role: "conjur_node"
    volumes:
      - ./:/src:z
      - ./log:/var/log/conjur   # exported conjur audit log
      - ./log:/var/log/nginx    # exported nginx audit log
    security_opt:
      - seccomp:unconfined
    restart: always
    networks:
      - mnetwk

  conjur2:
    image: conjur-appliance:latest
    container_name: conjur2     # important that container name == service name
    labels:
      role: "conjur_node"
    volumes:
      - ./:/src:z
      - ./log:/var/log/conjur   # exported conjur audit log
      - ./log:/var/log/nginx    # exported nginx audit log
    security_opt:
      - seccomp:unconfined
    restart: always
    networks:
      - mnetwk

  conjur3:
    image: conjur-appliance:latest
    container_name: conjur3     # important that container name == service name
    labels:
      role: "conjur_node"
    volumes:
      - ./:/src:z
      - ./log:/var/log/conjur   # exported conjur audit log
      - ./log:/var/log/nginx    # exported nginx audit log
    security_opt:
      - seccomp:unconfined
    restart: always
    networks:
      - mnetwk

  haproxy:
    image: haproxy:conjur
    hostname: conjur_proxy
    container_name: conjur_master
    build: ./build/haproxy
    labels:
      role: "conjur_proxy"
    volumes:
      - ./:/src:z
    ports:
      - 443:443
    restart: always
    entrypoint: "/start.sh"
    networks:
      - mnetwk
      - fnetwk

  cli:
    environment:
      CONJUR_ACCOUNT: dev
      CONJUR_APPLIANCE_URL: https://conjur_master/api
    container_name: conjur_cli
    hostname: conjur_cli
    image: my-conjurcli:5.4.0
    build: ./build/conjurcli
    volumes:
      - data:/data
      - ./:/src:z
      - "/var/run/docker.sock:/var/run/docker.sock:rw"  # enable docker commands from in container
      - "/usr/bin/docker:/usr/bin/docker:z"
    entrypoint: sleep
    command: infinity
    restart: always
    networks:
      - mnetwk
      - fnetwk

  scope:
    image: weaveworks/scope:1.6.5
    privileged: true
    ports:
      - "0.0.0.0:4040:4040"
    labels:
      - "works.weave.role=system"
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock:rw"
    command:
      - "--probe.docker=true"
    restart: always
    networks:
      - mnetwk

  follower:
    image: conjur-appliance:latest
    hostname: conjur_follower
    container_name: conjur_follower
    volumes:
      - ./:/src:z
    security_opt:
      - seccomp:unconfined
    restart: always
    networks:
      - fnetwk

# The webapp service is just a simple script running in a container - not really a web app.
# This service is brought up by the 1-setup-containers.sh script.
  webapp:
    image: webapp
    build: ./build/webapp
    volumes:
      - data:/data
    entrypoint: /root/webapp1.sh
    environment:
      - APP_HOSTNAME         # values for these variables are in .env file
      - VAR_ID               # written by 1-setup-containers.sh
      - SLEEP_TIME
    restart: always
    networks:
      - fnetwk

# VM containers for SSH management demonstrations.

# ssh access control and Ansible execution governed via Conjur policy
  vm:
    image: rack-vm:1.0
    labels:
      - "role=rack-vm"
    build: ./build/vm
    volumes:
      - .:/src
      - data:/data
    entrypoint: sleep
    command: infinity
    restart: always
    networks:
      - fnetwk

  ansible:
    container_name: ansible
    image: "ansible:alpine3"
    build: build/ansible
    environment:
      ANSIBLE_HOST_KEY_CHECKING: "false"
    volumes:
      - ./:/src:rw
      - ./scenarios/ssh_ansible/ansible_hosts:/etc/ansible/hosts:rw
    restart: always
    networks:
      - fnetwk

# ssh from outside_vm to protected_vm through bastion_server, governed by Conjur policy
  protected:
    image: rack-vm:1.0
    container_name: protected_vm
    hostname: protected_vm
    entrypoint: sleep
    command: infinity
    restart: always
    networks:
      - fnetwk

  bastion:
    image: rack-vm:1.0
    container_name: bastion_server
    hostname: bastion_server
    entrypoint: sleep
    command: infinity
    restart: always
    networks:
      - default
      - fnetwk

  outside:
    image: rack-vm:1.0
    container_name: outside_vm
    hostname: outside_vm
    volumes:
      - .:/src
    entrypoint: sleep
    command: infinity
    restart: always
    networks:
      - default           # all alone on "external" network

# Open LDAP server for ldap sync demonstration.
# This service is brought up by the ./ldap/0-setup-ldap.sh script.
  ldap:
    container_name: ldap_server
    image: osixia/openldap:1.1.7
    build: ./build/ldap
    restart: always
    volumes:
      - .:/src
    restart: always
    networks:
      - mnetwk

# Splunk enterprise server for Splunk monitoring demonstration.
# This requires the Conjur and Nginx logs be exported from the Conjur container.
# See volumes: specification for the Conjur service above.
# This service is brought up by the ./splunk/0-setup-splunk.sh script.
  splunk:
    container_name: splunk
    hostname: splunkenterprise
    image: splunk/splunk:7.0.0
    build: ./build/splunk
    environment:
      SPLUNK_START_ARGS: --accept-license
      SPLUNK_ENABLE_LISTEN: 9997
      SPLUNK_ADD: tcp 1514
    volumes:
      - ./log:/log
      - opt-splunk-etc:/opt/splunk/etc
      - opt-splunk-var:/opt/splunk/var
    ports:
      - "8000:8000"
      - "9997:9997"
      - "8088:8088"
      - "1514:1514"
    restart: always
    networks:
      - mnetwk

volumes:
  data:
  opt-splunk-etc:
  opt-splunk-var:

networks:
  mnetwk:
    driver: bridge
    ipam:
     config:
       - subnet: 10.5.0.0/16
         gateway: 10.5.0.1
  fnetwk:
    driver: bridge
    ipam:
     config:
       - subnet: 10.6.0.0/16
         gateway: 10.6.0.1
